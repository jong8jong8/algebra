### 6.8 Fitting Exponential Models to Data

- The exponential regression
$$ y = ab^x $$
    - $b > 1$: an exponential growth model
    - $0 < b < 1$: an exponential decay model 

- Using `numpy`'s `polyfit()` for the exponential regression:
$$ y = ab^x \\
 \ln(x) = \ln(ab^x) \\
 \ln(x) = \ln(a) + \ln(b^x) \\
 \ln(x) = \ln(a) + x\ln(b) \\
 \ln(x) = \ln(b)x + \ln(a) \\
 y^\prime = m^\prime x + b^\prime
$$
Thus,
$$ y^\prime = \ln{x} \\
m^\prime = \ln(b) \\
b^\prime = \ln(a)
$$
and this leads to
$$ a = e^{b^\prime}, \; b = e^{m^\prime} $$


- ðŸŽ¯ `jupyter-lab` practice

```
# Example 1

%matplotlib widget
import matplotlib.pyplot as plt
from matplotlib.figure import figaspect
import numpy as np

x = np.array([0, 0.01, 0.03, 0.05, 0.07, 0.09, 0.11, 0.13, 0.15, 0.17, 0.19, 0.21])
y = np.array([1, 1.03, 1.06, 1.38, 2.09, 3.54, 6.41, 12.6, 22.1, 39.05, 65.32, 99.78])

fig, ax = plt.subplots()
ax.scatter(x, y, color='r')

# See https://www.statology.org/exponential-regression-python/
m_prime, b_prime = np.polyfit(x, np.log(y), 1)

a = np.exp(b_prime)
b = np.exp(m_prime)
print(a, b)

y_fit = a*b**x
ax.plot(x, y_fit)

r = np.corrcoef(y, y_fit)[0][1] # correlation coefficient
print(r**2)

guess = a*b**(0.16)  # Example 1 b
print(guess)
ax.scatter(0.16, guess, color='b')

plt.grid(which='major', color='#666666', linestyle='-')
plt.minorticks_on()
plt.grid(which='minor', color='#999999', linestyle='-', alpha=0.2)

plt.xlim(0, 0.23)
plt.ylim(0, 120)
```


- The logarithmic regression
$$ y = a + b\ln(x),\; x \geq 0 $$
    - $b > 0$: the model is increasing
    - $b < 0$: the model is decreasing

- Using `numpy`'s `polyfit()` for the logarithmic regression:
$$ y = a + b \ln(x) \\ 
y = b \ln(x) + a \\
y = b x^\prime + a$$
Thus,
$$x^\prime = \ln(x) $$



- ðŸŽ¯ `jupyter-lab` practice

```
# Example 2

%matplotlib widget
import matplotlib.pyplot as plt
import numpy as np

x = np.arange(1, 13, 1)
y = np.array([47.3, 50.0, 54.1, 59.7, 62.9, 68.2, 69.7, 70.8, 73.7, 75.4, 76.8, 78.7])

fig, ax = plt.subplots()
ax.scatter(x, y, color='r')

b, a = np.polyfit(np.log(x), y, 1)
print(a, b)

y_fit = a + b*np.log(x)
ax.plot(x, y_fit)

r = np.corrcoef(y, y_fit)[0][1] # correlation coefficient
print(r**2)

guess = a + b*np.log(14)  # Example 2 b
print(guess)
ax.scatter(14, guess, color='b')

plt.grid(which='major', color='#666666', linestyle='-')
plt.minorticks_on()
plt.grid(which='minor', color='#999999', linestyle='-', alpha=0.2)

plt.xlim(0, 15)
plt.ylim(40, 90)
```


- The logistic regression
$$ y = \dfrac{c}{1 + e^{-bx}} $$
    - the initial value: $\dfrac{c}{1 + a}$
    - the model grow closer and closer to $y = c$


- ðŸŽ¯ `jupyter-lab` practice

```
# Example 3

%matplotlib widget
import matplotlib.pyplot as plt
import scipy.optimize as opt
import numpy as np

x = np.arange(0, 18, 1)
y = np.array([12.69, 16.35, 20.29, 25.08, 30.81, 38.75, 45.00, 49.16, 55.15, 62.852, 68.63, 76.64, 82.47, 85.68, 89.14, 91.86, 95.28, 98.17])


fig, ax = plt.subplots()
ax.scatter(x, y, color='r')

def logistic_model(x, a, b, c):
    return c / (1 + a*np.exp(-b * x))

popt, pcov = opt.curve_fit(logistic_model, x, y, method="trf")

print(popt)

a = popt[0]
b = popt[1]
c = popt[2]

y_fit = logistic_model(x, a, b, c)
ax.plot(x, y_fit)

r = np.corrcoef(y, y_fit)[0][1] # correlation coefficient
print(r**2)

guess = logistic_model(18, a, b, c)  # Example 3 b
print(guess)
ax.scatter(18, guess, color='b')

plt.grid(which='major', color='#666666', linestyle='-')
plt.minorticks_on()
plt.grid(which='minor', color='#999999', linestyle='-', alpha=0.2)

plt.xlim(0, 20)
plt.ylim(10, 110)
```
